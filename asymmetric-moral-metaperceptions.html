<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Asymmetric Moral Metaperceptions - Yalda Daryani</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 0;
            color: #333;
        }
        
        /* Navigation Bar Styles */
        .navbar {
            background-color: #f8f8f8;
            padding: 15px 0;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            width: 100%;
        }
        
        .navbar a {
            color: #333;
            text-decoration: none;
            margin: 0 15px;
            font-weight: 500;
            font-size: 16px;
            transition: color 0.3s;
        }
        
        .navbar a:hover {
            color: #0366d6;
        }
        
        .content {
            padding: 0 20px;
        }
        
        .project-header {
            margin-bottom: 40px;
            text-align: center;
        }
        
        .project-title {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #333;
        }
        
        .project-subtitle {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 20px;
        }
        
        .project-links {
            margin: 20px 0;
        }
        
        .project-links a {
            display: inline-block;
            margin: 0 10px;
            padding: 8px 15px;
            background-color: #0366d6;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-weight: bold;
            transition: background-color 0.3s;
        }
        
        .project-links a:hover {
            background-color: #0353b3;
        }
        
.project-image {
    display: block;
    margin: 0 auto;        /* centers the image */
    max-width: 80%;        /* scale down so it doesnâ€™t take full width */
    max-height: 400px;     /* keeps it from being too tall */
    object-fit: contain;   /* ensures the whole image is visible */
    border-radius: 8px;
    margin-bottom: 30px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}

        
        .project-section {
            margin-bottom: 40px;
        }
        
        .project-section h2 {
            border-bottom: 2px solid #eaecef;
            padding-bottom: 10px;
            color: #24292e;
        }
        
        .two-column {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
        }
        
        .column {
            flex: 1;
            min-width: 300px;
        }
        
        .timeline {
            position: relative;
            padding-left: 30px;
        }
        
        .timeline-item {
            margin-bottom: 30px;
            position: relative;
        }
        
        .timeline-item:before {
            content: "";
            position: absolute;
            left: -30px;
            top: 5px;
            width: 15px;
            height: 15px;
            border-radius: 50%;
            background-color: #0366d6;
        }
        
        .timeline-item:after {
            content: "";
            position: absolute;
            left: -23px;
            top: 20px;
            bottom: -15px;
            width: 2px;
            background-color: #e1e4e8;
        }
        
        .timeline-item:last-child:after {
            display: none;
        }
        
        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 15px;
        }
        
        .tech-tag {
            padding: 5px 10px;
            background-color: #f1f8ff;
            border: 1px solid #c8e1ff;
            border-radius: 3px;
            font-size: 0.9em;
            color: #0366d6;
        }
        
        .citation {
            background-color: #f6f8fa;
            border-left: 4px solid #0366d6;
            padding: 15px;
            margin: 20px 0;
            font-family: monospace;
            white-space: pre-wrap;
        }
        
        .team-members {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin-top: 20px;
        }
        
        .team-member {
            text-align: center;
            width: 120px;
        }
        
        .team-member img {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            object-fit: cover;
        }
        
        .team-member p {
            margin: 5px 0 0 0;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <div class="navbar">
        <a href="index.html">Home</a>
        <a href="publications.html">Publications</a>
        <a href="service.html">Service</a>
        <a href="talks.html">Talks and Presentations</a>
        <a href="cv.html">Resume/CV</a>
    </div>

    <div class="content">
        <div class="project-header">
            <h1 class="project-title">When We Get Each Other Wrong: Using NLP and Behavioral Experiments to Correct Misperceptions</h1>
            <p class="project-subtitle">Analyzing 10M Tweets and 2,400 Participants to Understand and Correct Moral Biases</p>
            
            <div class="project-links">
                <a href="#" target="_blank">GitHub Code (WIP)</a>
                </div>
            
            <img src="MOLA.jpg" alt="Visualization of Moral Perceptions and Metaperceptions" class="project-image">
        </div>
        
        <div class="project-section">
            <h2>Overview</h2>
            <p>
                This project examines how people misjudge what their political opponents think of their moral values and how these errors sustain division. Using computational analyses of <strong>10M+</strong> tweets and <strong>three large-scale experiments</strong>, I show that misperceptions of moral values increase distrust and perceived threat. Importantly, I test a <strong>scalable, data-driven intervention</strong> that improves intergroup trust.
            </p>
        </div>
        
        <div class="project-section two-column">
            <div class="column">
                <h2>Key Contributions</h2>
                <ul>
                    <li><strong>Large-Scale NLP & Social Media Analytics:</strong> Analyzed 10+M tweets utilizing machine learning and AI-based approaches to identify how moral language frames abortion debates.</li>
                    <li><strong>Experimental Research Design:</strong> Conducted three preregistered experiments (N > 2,300) to test psychological mechanisms of misperception.</li>
                    <li><strong>Predictive Modeling:</strong> Applied logistic regression & random forest models to quantify how moral framing predicts political stance.</li>
                    <li><strong>Informational Intervention:</strong> Designed and validated a low-cost behavioral intervention that improved intergroup trust across divides.</li>
                </ul>
            </div>
            <div class="column">
                <h2>My Research Toolkit</h2>
                <p>The project leveraged state-of-the-art computational and experimental techniques across four studies to ensure robustness and generalizability.</p>
                <div class="tech-stack">
                    <span class="tech-tag">R</span>
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">Natural Language Processing (NLP)</span>
                    <span class="tech-tag">Machine Learning (Random Forest, classification models)</span>
                    <span class="tech-tag">GPT-3.5 Turbo (Annotation)</span>
                    <span class="tech-tag">Statistical Modeling (MANCOVA, regression, moderation)</span>
                    <span class="tech-tag">Experimental Design & Causal Inference</span>
                    <span class="tech-tag">Survey Design & Large-Scale Online Data Collection</span>
                </div>
            </div>
        </div>
        
        <div class="project-section">
            <h2>Methodology Timeline (4 Studies)</h2>
            <div class="timeline">
                <div class="timeline-item">
                    <h3>Study 1: Identifying Moral Framing in Twitter Discourse (Computational)</h3>
                    <p>
                        
Analyzed <strong>10M million tweets</strong> on the abortion debate to confirm that moral language use differs when discussing ingroup stance versus outgroup positions. I <strong>created detailed annotation guidelines</strong> to train supervised models and conducted <strong>prompt engineering</strong> when using AI-assisted annotation. Employed fine-tuned <strong>BERTweet</strong> for stance classification (Macro F1 = 0.758) and <strong>RoBERTa</strong> for moral foundation tagging, establishing the foundational role of morality in the conflict. For data analysis, I applied both <strong>logistic regression</strong> and <strong>random forest models</strong> to validate predictive relationships and capture non-linear patterns.
                    </p>
                </div>
                
                <div class="timeline-item">
                    <h3>Study 2 & 3: Measuring Asymmetric Misperceptions (Experimental)</h3>
                    <p>
                        Used a <strong>2 (Group) x 3 (Condition: Ingroup, Outgroup, Metaperception)</strong> experimental design to measure moral and social perceptions, including <strong>warmth</strong>, <strong>competence</strong>, and <strong>social distance</strong>, across the <strong>abortion</strong> and <strong>gun control</strong> issues. Quantified the mismatch between the outgroup's <em>actual</em> rating and the ingroup's <em>predicted</em> rating, confirming robust asymmetric biases across political contexts. For data analysis, I applied <strong>MANCOVA</strong> and <strong>MANOVA</strong> to test group differences while controlling for ideology. This approach provided a rigorous assessment of both <strong>multivariate outcomes</strong> and <strong>interaction effects</strong>, offering a comprehensive picture of how misperceptions shape intergroup trust and perceived threat.
                    </p>
                </div>
                
                <div class="timeline-item">
                    <h3>Study 4: Testing Corrective Feedback (Intervention)</h3>
                    <p>
                        Conducted a N > 1,200 experiment where participants received false but plausible feedback (Better-Than-Expected, Worse-Than-Expected, Control) on how the outgroup morally evaluated them. Measured subsequent changes in <strong>intergroup trust</strong> and <strong>perceived threat</strong> as the primary outcomes.
                    </p>
                </div>
                
            </div>
        </div>
        
        <div class="project-section">
            <h2>Results and Implications</h2>
            <p>
                The results provide clear evidence that <strong>moral metaperceptions are malleable</strong> and act as a leverage point for depolarization.
            </p>
            <ul>
                <li><strong>Correction Works:</strong> Showing participants that the other side rated them more positively than expected increased trust and reduced threat.</li>
                <li><strong>Empathy Matters:</strong> Interventions were most effective among high-empathy individuals, highlighting moderators of impact.</li>
                <li><strong>Applied Insight:</strong> Demonstrates how psychological biases can be corrected with data-driven, scalable methods, relevant for addressing bias in workplaces, platforms, and AI systems.</li>
            </ul>
        </div>
        
        <div class="project-section">
            <h2>Publication</h2>
            <p>
                This work was conducted as a major component of my doctoral research and is currently under review for publication.
            </p>

        </div>
        
        <div class="project-section">
            <h2>Team</h2>
            <p>This was a collaborative research project in which I served as the <strong>lead researcher</strong>. I worked closely with <strong>computer science collaborators</strong> who contributed to model development and technical implementation.
</p>
            <div class="team-members">
                <div class="team-member">
                    <img src="profile.jpg" alt="Yalda Daryani">
                    <p><strong>Yalda Daryani</strong></p>
                    <p>Lead Author & Researcher</p>
                </div>
                <div class="team-member">
                    <img src="parsa.jpg" alt="Parsa Hejabi">
                    <p><strong>Parsa Hejabi</strong></p>
                    <p>Co-Author & Collaborator</p>
                </div>
                <div class="team-member">
                    <img src="morteza.jpg" alt="Morteza Dehghani">
                    <p><strong>Morteza Dehghani</strong></p>
                    <p>Principal Investigator & Advisor</p>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
